{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as num\n",
    "import scipy as sci\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import sklearn as skl\n",
    "import xgboost\n",
    "import gensim\n",
    "import json\n",
    "import re\n",
    "import string\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a fraction of the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingAmount = 10000\n",
    "testAmount = 2500\n",
    "\n",
    "with open('review.json') as raw:\n",
    "    with open('training.json', 'w') as trainingSet: \n",
    "        for x in range(trainingAmount):\n",
    "            line = raw.readline()\n",
    "            trainingSet.write(line)\n",
    "    with open('test.json', 'w') as testSet: \n",
    "        for x in range(trainingAmount, trainingAmount+testAmount):\n",
    "            line = raw.readline()\n",
    "            testSet.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_json('training.json', lines=True)\n",
    "df_test = pd.read_json('test.json', lines=True)\n",
    "\n",
    "df_test = df_test.drop(\"review_id\", axis=1).drop(\"business_id\", axis=1).drop(\"user_id\", axis=1).drop(\"date\", axis=1)\n",
    "df_test = df_test.reindex(['text','stars','useful','funny','cool'], axis=1)\n",
    "\n",
    "df_train = df_train.drop(\"review_id\", axis=1).drop(\"business_id\", axis=1).drop(\"user_id\", axis=1).drop(\"date\", axis=1)\n",
    "df_train = df_train.reindex(['text','stars','useful','funny','cool'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the clean method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    from nltk.stem.snowball import SnowballStemmer\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    \n",
    "#     lemmatizer = WordNetLemmatizer()\n",
    "#     for word in text:\n",
    "#         word = lemmatizer.lemmatize(word)\n",
    "    \n",
    "     # Empty question\n",
    "    if type(text) != str:\n",
    "        return ''\n",
    "    \n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "    \n",
    "#     text = re.sub(\"I\\'ll\", \"I will\", text)\n",
    "#     text = re.sub(\"I\\'m\", \"I am\", text)\n",
    "\n",
    "#     text = text.lower()\n",
    "    \n",
    "#     text = re.sub(\" what\\'s \", \" what is \", text)\n",
    "#     text = re.sub(\" that\\'s \", \" that is \", text)\n",
    "    \n",
    "#     text = re.sub(\"\\'s\", \"\", text)\n",
    "#     text = re.sub('\\n', ' ', text)\n",
    "    \n",
    "    \n",
    "#     text = re.sub(\" whats \", \" what is \", text)\n",
    "#     text = re.sub(\" thats \", \" that is \", text)\n",
    "#     text = re.sub(\"\\'ve\", \" have \", text)\n",
    "#     text = re.sub(\"n\\'t\", ' not', text)\n",
    "\n",
    "    text = re.sub('[' + string.punctuation + ']', '', text)\n",
    "    \n",
    "    # remove comma between numbers, i.e. 15,000 -> 15000\n",
    "    text = re.sub('(?<=[0-9])\\,(?=[0-9])', \"\", text)\n",
    "\n",
    "    \n",
    "    #Tokenizing text for normalizing more easily\n",
    "    tokenized_text = word_tokenize(text)\n",
    "    \n",
    "    #Removing stopwords\n",
    "    tokenized_text = [w for w in tokenized_text if not w in stopwords] \n",
    "    \n",
    "    #Stemming\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    textList = word_tokenize(text)\n",
    "    for word in textList:\n",
    "        word += stemmer.stem(word)\n",
    "    \n",
    "    #Putting tokens back together as a string\n",
    "    text = ''\n",
    "    for token in tokenized_text:\n",
    "        text += text + ' '\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Return a list of words\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['length'] = df_train['text'].apply(len)\n",
    "df_test['length'] = df_test['text'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.716700</td>\n",
       "      <td>1.29820</td>\n",
       "      <td>0.458000</td>\n",
       "      <td>0.559000</td>\n",
       "      <td>581.699600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.471549</td>\n",
       "      <td>2.90264</td>\n",
       "      <td>1.557973</td>\n",
       "      <td>2.056682</td>\n",
       "      <td>547.943392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>231.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>414.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>737.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>91.00000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>4998.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              stars       useful         funny          cool        length\n",
       "count  10000.000000  10000.00000  10000.000000  10000.000000  10000.000000\n",
       "mean       3.716700      1.29820      0.458000      0.559000    581.699600\n",
       "std        1.471549      2.90264      1.557973      2.056682    547.943392\n",
       "min        1.000000      0.00000      0.000000      0.000000      2.000000\n",
       "25%        3.000000      0.00000      0.000000      0.000000    231.000000\n",
       "50%        4.000000      0.00000      0.000000      0.000000    414.000000\n",
       "75%        5.000000      1.00000      0.000000      0.000000    737.000000\n",
       "max        5.000000     91.00000     42.000000     86.000000   4998.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['cleaned_text'] = df_train['text'].apply(clean)\n",
    "df_test['cleaned_text'] = df_test['text'].apply(clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving all the necessary data in arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_train['cleaned_text'].values\n",
    "test = df_test['cleaned_text'].values\n",
    "trainStars = df_train['stars'].values\n",
    "testStars = df_test['stars'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BOW model with Na√Øve Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "trainVecs = vectorizer.fit_transform(train)\n",
    "testVecs = vectorizer.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifierNB = MultinomialNB()\n",
    "classifierNB.fit(trainVecs, trainStars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testStars_predicted = classifierNB.predict(testVecs)\n",
    "print(classifierNB.score(testVecs, testStars)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(testStars, testStars_predicted, labels=None, sample_weight=None)\n",
    "\n",
    "df_cm = pd.DataFrame(confusion_matrix, index = [i for i in \"12345\"],\n",
    "                  columns = [i for i in \"12345\"])\n",
    "plt.figure(figsize = (10,7))\n",
    "sns.heatmap(df_cm, annot=True, fmt='g')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_percentage = confusion_matrix / df_train.shape[0] * 100\n",
    "\n",
    "df_cm = pd.DataFrame(confusion_matrix_percentage, index = [i for i in \"12345\"],\n",
    "                  columns = [i for i in \"12345\"])\n",
    "plt.figure(figsize = (10,7))\n",
    "sns.heatmap(df_cm, annot=True, fmt='g')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_proportions = []\n",
    "for n in range(confusion_matrix.shape[0]):\n",
    "    confusion_matrix_proportions.append(confusion_matrix[n,:]/df_test.groupby('stars').count().at[n+1, 'text']*100)\n",
    "    \n",
    "confusion_matrix_proportions = num.array(confusion_matrix_proportions)\n",
    "\n",
    "df_cm = pd.DataFrame(confusion_matrix_proportions, index = [i for i in \"12345\"],\n",
    "                  columns = [i for i in \"12345\"])\n",
    "plt.figure(figsize = (10,7))\n",
    "sns.heatmap(df_cm, annot=True, fmt='g')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "distance = num.abs(testStars - testStars_predicted)\n",
    "collections.Counter(distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "train_tokenized = [word_tokenize(token) for token in train]\n",
    "test_tokenized = [word_tokenize(token) for token in test]\n",
    "\n",
    "word2vec = Word2Vec(train_tokenized, min_count=5)\n",
    "\n",
    "word2vec.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent2vec(reviewTok):\n",
    "    vecSize = len(word2vec.wv[reviewTok[0][0]])\n",
    "    reviewVec = []\n",
    "    for sentence in reviewTok:\n",
    "        vectorSum = num.zeros(vecSize)\n",
    "        empty = True\n",
    "        for token in sentence:\n",
    "            if token in word2vec.wv.vocab:\n",
    "                vectorSum += word2vec.wv[token]\n",
    "                empty = False\n",
    "        if not empty:\n",
    "            vectorSum = vectorSum / num.sqrt((vectorSum ** 2).sum())\n",
    "        reviewVec.append(vectorSum)\n",
    "    return num.array(reviewVec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = sent2vec(train_tokenized)\n",
    "test_vectors = sent2vec(test_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgbclassifier = XGBClassifier()\n",
    "xgbclassifier.fit(train_vectors, trainStars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xgbclassifier.score(test_vectors, testStars)*100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking for relation between text length and rating\n",
    "Tests with charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(data=df_test, col='stars')\n",
    "g.map(plt.hist, 'length', bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='stars', y='length', data=df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starProp_train = df_train.groupby('stars').count().drop('useful', axis=1).drop('funny', axis=1).drop('cool', axis=1).drop('length', axis=1)\n",
    "starProp_train['percentage'] = starProp_train['cleaned_text'] / df_train.shape[0] * 100\n",
    "starProp_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starProp_test = df_test.groupby('stars').count().drop('useful', axis=1).drop('funny', axis=1).drop('cool', axis=1).drop('length', axis=1)\n",
    "starProp_test['percentage'] = starProp_test['cleaned_text'] / df_test.shape[0] * 100\n",
    "starProp_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and test set have same proportions! :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ideas:\n",
    "- make a numbers token <NUMBER>\n",
    "- stem the words\n",
    "- remove stopwords\n",
    "- create a personal noun token <PERSONALNOUN>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "review = word_tokenize(df_test['cleaned_text'].values[4])\n",
    "stemmed = ''\n",
    "for word in review:\n",
    "    stemmed += stemmer.stem(word) + ' '\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
